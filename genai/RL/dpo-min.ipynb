{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-25T09:34:09.857396Z",
     "start_time": "2025-08-25T09:34:01.412626Z"
    }
   },
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from trl import DPOTrainer, DPOConfig\n",
    "from datasets import Dataset\n",
    "\n",
    "# 1. Load base instruction model and tokenizer\n",
    "model_name = \"google/flan-t5-small\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 2. Larger dummy preference dataset\n",
    "samples = [\n",
    "    {\"prompt\": \"Translate 'Hello' to French:\", \"chosen\": \"Bonjour\", \"rejected\": \"Hola\"},\n",
    "    {\"prompt\": \"What is 2+2?\", \"chosen\": \"4\", \"rejected\": \"5\"},\n",
    "    {\"prompt\": \"Translate 'Thank you' to Spanish:\", \"chosen\": \"Gracias\", \"rejected\": \"Merci\"},\n",
    "    {\"prompt\": \"What is the capital of France?\", \"chosen\": \"Paris\", \"rejected\": \"Florida\"},\n",
    "    {\"prompt\": \"Translate 'Good morning' to German:\", \"chosen\": \"Guten Morgen\", \"rejected\": \"Buenos Dias\"},\n",
    "    {\"prompt\": \"What is 3x3?\", \"chosen\": \"9\", \"rejected\": \"6\"},\n",
    "    {\"prompt\": \"Translate 'I love you' to Italian:\", \"chosen\": \"Ti amo\", \"rejected\": \"Te amo\"},\n",
    "    {\"prompt\": \"What is the largest planet?\", \"chosen\": \"Jupiter\", \"rejected\": \"Mars\"},\n",
    "    {\"prompt\": \"Translate 'Goodbye' to Japanese:\", \"chosen\": \"Sayonara\", \"rejected\": \"Adios\"},\n",
    "    {\"prompt\": \"What is 5-2?\", \"chosen\": \"3\", \"rejected\": \"4\"},\n",
    "]\n",
    "train_dataset = Dataset.from_list(samples[:8])\n",
    "eval_dataset = Dataset.from_list(samples[8:])\n",
    "\n",
    "# 3. Verify dataset format\n",
    "def verify_dataset(example):\n",
    "    assert all(k in example for k in [\"prompt\", \"chosen\", \"rejected\"]), \"Missing keys\"\n",
    "    return example\n",
    "\n",
    "train_dataset = train_dataset.map(verify_dataset)\n",
    "eval_dataset = eval_dataset.map(verify_dataset)\n",
    "\n",
    "# 4. Training args\n",
    "args = DPOConfig(\n",
    "    output_dir=\"./dpo_flan_t5\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=5,\n",
    "    logging_steps=1,\n",
    "    save_strategy=\"no\",\n",
    "    learning_rate=3e-5,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=[],\n",
    "    beta=0.1,\n",
    "    max_length=128,\n",
    "    max_prompt_length=64,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=2,\n",
    ")\n",
    "\n",
    "# 5. DPO Trainer\n",
    "trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    ref_model=None,   # reference model auto-created\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "\n",
    "# 6. Train\n",
    "trainer.train()\n",
    "\n",
    "# 7. Save model\n",
    "trainer.model.save_pretrained(\"./dpo_flan_t5_model\")\n",
    "tokenizer.save_pretrained(\"./dpo_flan_t5_model\")\n",
    "\n",
    "# 8. Inference with trained model\n",
    "def generate(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(trainer.model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = trainer.model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=30,\n",
    "            num_beams=4,\n",
    "            early_stopping=True,\n",
    "        )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "# Test\n",
    "test_prompt = \"Translate 'I am going to school' to French:\"\n",
    "print(\"\\nGenerated Response:\\n\", generate(test_prompt))\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/8 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6a99b8c7015f4422820c145343068031"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "edfaefbee89c4bd9807538b7a588d7aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Extracting prompt in train dataset:   0%|          | 0/8 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "272eebb7c3584015b8c11da2faf0a108"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/8 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1c10da5a08a49cfa723581f849d97be"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/8 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd8c0631daca47eaa1df177ee80d900c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Extracting prompt in eval dataset:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9c9e9852c3c47e0b6080c3ab6a8aed7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ffe5a82b1f3748bab7d2d9866395dea2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e563b067f85a46cf945b5de90898674a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:04, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rewards/chosen</th>\n",
       "      <th>Rewards/rejected</th>\n",
       "      <th>Rewards/accuracies</th>\n",
       "      <th>Rewards/margins</th>\n",
       "      <th>Logps/chosen</th>\n",
       "      <th>Logps/rejected</th>\n",
       "      <th>Logits/chosen</th>\n",
       "      <th>Logits/rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.746700</td>\n",
       "      <td>0.698322</td>\n",
       "      <td>-0.014705</td>\n",
       "      <td>-0.004424</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.010281</td>\n",
       "      <td>-16.599310</td>\n",
       "      <td>-13.265632</td>\n",
       "      <td>-14.172015</td>\n",
       "      <td>-12.658319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.705713</td>\n",
       "      <td>-0.029208</td>\n",
       "      <td>-0.004395</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.024812</td>\n",
       "      <td>-16.744335</td>\n",
       "      <td>-13.265342</td>\n",
       "      <td>-14.281544</td>\n",
       "      <td>-12.759686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.629000</td>\n",
       "      <td>0.709102</td>\n",
       "      <td>-0.046065</td>\n",
       "      <td>-0.014675</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.031390</td>\n",
       "      <td>-16.912905</td>\n",
       "      <td>-13.368136</td>\n",
       "      <td>-14.374640</td>\n",
       "      <td>-12.838968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.644600</td>\n",
       "      <td>0.713161</td>\n",
       "      <td>-0.064511</td>\n",
       "      <td>-0.025329</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.039182</td>\n",
       "      <td>-17.097366</td>\n",
       "      <td>-13.474674</td>\n",
       "      <td>-14.432551</td>\n",
       "      <td>-12.881265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.496600</td>\n",
       "      <td>0.711789</td>\n",
       "      <td>-0.069058</td>\n",
       "      <td>-0.032512</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.036546</td>\n",
       "      <td>-17.142838</td>\n",
       "      <td>-13.546513</td>\n",
       "      <td>-14.501986</td>\n",
       "      <td>-12.926527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.676400</td>\n",
       "      <td>0.714571</td>\n",
       "      <td>-0.084044</td>\n",
       "      <td>-0.042260</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.041784</td>\n",
       "      <td>-17.292694</td>\n",
       "      <td>-13.643986</td>\n",
       "      <td>-14.560690</td>\n",
       "      <td>-12.992306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.523000</td>\n",
       "      <td>0.717714</td>\n",
       "      <td>-0.085411</td>\n",
       "      <td>-0.037593</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.047818</td>\n",
       "      <td>-17.306368</td>\n",
       "      <td>-13.597322</td>\n",
       "      <td>-14.562527</td>\n",
       "      <td>-12.985661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>0.718935</td>\n",
       "      <td>-0.090730</td>\n",
       "      <td>-0.040626</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.050104</td>\n",
       "      <td>-17.359560</td>\n",
       "      <td>-13.627646</td>\n",
       "      <td>-14.597715</td>\n",
       "      <td>-13.019164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.651300</td>\n",
       "      <td>0.717553</td>\n",
       "      <td>-0.091259</td>\n",
       "      <td>-0.043726</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.047533</td>\n",
       "      <td>-17.364851</td>\n",
       "      <td>-13.658651</td>\n",
       "      <td>-14.610106</td>\n",
       "      <td>-13.024620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.755300</td>\n",
       "      <td>0.720287</td>\n",
       "      <td>-0.096043</td>\n",
       "      <td>-0.043275</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.052767</td>\n",
       "      <td>-17.412683</td>\n",
       "      <td>-13.654140</td>\n",
       "      <td>-14.599330</td>\n",
       "      <td>-13.018983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Response:\n",
      " Je vais à l'école\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "45fc86d2d3c8bc3e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
