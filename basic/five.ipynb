{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "#1. Basic Neural Network (Feedforward / MLP)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=[4,]),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='softmax'),\n",
    "])\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#2. Convolutional Neural Network (CNN)\n",
    "model=tf.keras.Sequential([\n",
    "    layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='softmax'),\n",
    "])\n",
    "#history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10)"
   ],
   "id": "1f24d35d603e25d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "datagen=ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    rotation_range=90,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")"
   ],
   "id": "1d22431b4e6e4c10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Early Stopping & Model Checkpointing\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True),\n",
    "]"
   ],
   "id": "fda185aafba0ed4e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "lr=ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=0.0001)"
   ],
   "id": "5f1f765f31307aad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ],
   "id": "f279aa37e396c67",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    rotation_range=90,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    ")\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    \"data/train\", target_size=(224, 224), batch_size=32, shuffle=True, seed=42, class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "val_data = train_datagen.flow_from_directory(\n",
    "    \"data/val\", target_size=(224, 224), batch_size=32, shuffle=True, seed=42, class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(train_data.num_classes, activation='softmax'),\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=0.0001)\n",
    "]\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks\n",
    ")"
   ],
   "id": "4f1da8313f136cde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "vocab_size = 10000\n",
    "max_length = 200\n",
    "(X_train, y_train), (X_val, y_val) = imdb.load_data(num_words=vocab_size)\n",
    "X_train = pad_sequences(X_train, maxlen=max_length)\n",
    "X_val = pad_sequences(X_val, maxlen=max_length)\n",
    "\n",
    "model=models.Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=128, input_length=max_length),\n",
    "    layers.SpatialDropout1D(0.2),\n",
    "    layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    layers.Dense(64, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=0.0001)\n",
    "]\n",
    "\n",
    "#history =model.fit(X_train, y_train, epochs=10, batch_size=32, callbacks=callbacks)"
   ],
   "id": "e2649e3493fe5bdb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T05:49:16.992472Z",
     "start_time": "2025-08-12T05:49:14.258606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab_size = 10000\n",
    "max_length = 200\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "X_train = pad_sequences(X_train, maxlen=max_length)\n",
    "X_test = pad_sequences(X_test, maxlen=max_length)\n",
    "\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    #Self-attention\n",
    "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads)(inputs, inputs)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + inputs)\n",
    "\n",
    "    #feedforward\n",
    "    ff = layers.Dense(ff_dim, activation='relu')(x)\n",
    "    ff = layers.Dense(inputs.shape[-1])(ff)\n",
    "    x = layers.Dropout(dropout)(ff)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x+ff)\n",
    "    return x\n",
    "\n",
    "\n",
    "inputs = layers.Input(shape=(max_length,))\n",
    "x = layers.Embedding(input_dim=vocab_size, output_dim=64)(inputs)\n",
    "positions = tf.range(start=0, limit=max_length, delta=1)\n",
    "pos_embedding_layer = layers.Embedding(input_dim=max_length, output_dim=64)(positions)\n",
    "x = x + pos_embedding_layer\n",
    "\n",
    "x = transformer_encoder(x, head_size=64, num_heads=16, ff_dim=64, dropout=0.2)\n",
    "x = transformer_encoder(x, head_size=64, num_heads=16, ff_dim=64, dropout=0.2)\n",
    "\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = models.Model(inputs, outputs)\n",
    "model.summary()"
   ],
   "id": "b31756bf4c403574",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, 200)]                0         []                            \n",
      "                                                                                                  \n",
      " embedding_9 (Embedding)     (None, 200, 64)              640000    ['input_5[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_12 (T  (None, 200, 64)              0         ['embedding_9[0][0]']         \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (Mu  (None, 200, 64)              265280    ['tf.__operators__.add_12[0][0\n",
      " ltiHeadAttention)                                                  ]',                           \n",
      "                                                                     'tf.__operators__.add_12[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)        (None, 200, 64)              0         ['multi_head_attention_7[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_13 (T  (None, 200, 64)              0         ['dropout_15[0][0]',          \n",
      " FOpLambda)                                                          'tf.__operators__.add_12[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_12 (La  (None, 200, 64)              128       ['tf.__operators__.add_13[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " dense_20 (Dense)            (None, 200, 64)              4160      ['layer_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_21 (Dense)            (None, 200, 64)              4160      ['dense_20[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)        (None, 200, 64)              0         ['dense_21[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_14 (T  (None, 200, 64)              0         ['dropout_16[0][0]',          \n",
      " FOpLambda)                                                          'dense_21[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_13 (La  (None, 200, 64)              128       ['tf.__operators__.add_14[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (Mu  (None, 200, 64)              265280    ['layer_normalization_13[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)        (None, 200, 64)              0         ['multi_head_attention_8[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_15 (T  (None, 200, 64)              0         ['dropout_17[0][0]',          \n",
      " FOpLambda)                                                          'layer_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_14 (La  (None, 200, 64)              128       ['tf.__operators__.add_15[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " dense_22 (Dense)            (None, 200, 64)              4160      ['layer_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_23 (Dense)            (None, 200, 64)              4160      ['dense_22[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)        (None, 200, 64)              0         ['dense_23[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_16 (T  (None, 200, 64)              0         ['dropout_18[0][0]',          \n",
      " FOpLambda)                                                          'dense_23[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_15 (La  (None, 200, 64)              128       ['tf.__operators__.add_16[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " global_max_pooling1d_2 (Gl  (None, 64)                   0         ['layer_normalization_15[0][0]\n",
      " obalMaxPooling1D)                                                  ']                            \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)        (None, 64)                   0         ['global_max_pooling1d_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_24 (Dense)            (None, 64)                   4160      ['dropout_19[0][0]']          \n",
      "                                                                                                  \n",
      " dense_25 (Dense)            (None, 1)                    65        ['dense_24[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1191937 (4.55 MB)\n",
      "Trainable params: 1191937 (4.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, head_size, num_heads, ff_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads)\n",
    "        self.ffn = models.Sequential([\n",
    "            layers.Dense(ff_dim, activation=\"relu\"),\n",
    "            layers.Dense(head_size * num_heads),\n",
    "        ])\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(dropout)\n",
    "        self.dropout2 = layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        out1 = self.layernorm1(inputs + self.dropout1(attn_output, training=training))\n",
    "        ffn_output = self.ffn(out1)\n",
    "        return self.layernorm2(out1 + self.dropout2(ffn_output, training=training))\n",
    "\n",
    "# Step 4: Build the Model\n",
    "def build_model():\n",
    "    inputs = layers.Input(shape=(max_length,))\n",
    "    x = layers.Embedding(input_dim=vocab_size, output_dim=64)(inputs)\n",
    "\n",
    "    # Positional Encoding\n",
    "    positions = tf.range(start=0, limit=max_length, delta=1)\n",
    "    pos_embedding = layers.Embedding(input_dim=max_length, output_dim=64)(positions)\n",
    "    x = x + pos_embedding\n",
    "\n",
    "    # Transformer Blocks\n",
    "    x = TransformerBlock(head_size=64, num_heads=2, ff_dim=64, dropout=0.1)(x)\n",
    "    x = TransformerBlock(head_size=64, num_heads=2, ff_dim=64, dropout=0.1)(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Step 5: Compile Model\n",
    "model = build_model()\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n"
   ],
   "id": "b1702e9ef0aaf76b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "import tensorflow as tf\n",
    "\n",
    "dataset = load_dataset(\"imdb\")\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "train_data = dataset[\"train\"].select(range(10000))  # Smaller for speed\n",
    "test_data = dataset[\"test\"].select(range(5000))\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, padding=True)\n",
    "\n",
    "train_data = train_data.map(tokenize, batched=True)\n",
    "test_data = test_data.map(tokenize, batched=True)\n",
    "\n",
    "# Step 5: Convert to tf.data.Dataset\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n",
    "\n",
    "tf_train = train_data.to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\"],\n",
    "    label_cols=[\"label\"],\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "tf_test = test_data.to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\"],\n",
    "    label_cols=[\"label\"],\n",
    "    shuffle=False,\n",
    "    batch_size=32,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(tf_train, validation_data=tf_test, epochs=3)\n",
    "\n",
    "# Step 8: Evaluate\n",
    "loss, acc = model.evaluate(tf_test)\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n"
   ],
   "id": "d73054a8013e65ab",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
